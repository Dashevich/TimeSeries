P.S. к предыдущему дз(не знаю где еще писать) - в комментариях было написано, что нет ответов на вопросы, но ответы на вопросы присутствовали в отчете. Может это было не прям в явном виде типа вопрос ответ. Но я описала классы и методы, сказала какие модели использовала и почему, какие метрики использовала и почему. Визуализация графиков и значения метрик также приводились в выводе модели.
## **Отчет**

### Описание реализованных классов и методов
**1. Класс `TimeSeriesProcessor`**  
Базовый класс для предобработки временных рядов:
- `remove_leading_zeros()`: Удаляет начальные нули в ряде, если их количество превышает 100 дней.
- `handle_outliers()`: Обнаруживает выбросы с помощью `IsolationForest` и заменяет их скользящей медианой.
- `inverse_transform()`: Выполняет обратное преобразование прогноза (например, после логарифмирования).
- `preprocess()`: Объединяет все этапы предобработки (удаление нулей, обработка выбросов, преобразование данных).

**2. Класс `TimeSeriesAnalysis`**  
Наследуется от `TimeSeriesProcessor` и выполняет анализ временных рядов:
- `run_analysis()`: Запускает полный анализ, включая:
  - Проверку тренда (линейная регрессия).
  - Анализ сезонности (сезонная декомпозиция, Фурье-спектр).
  - Тесты на стационарность (ADF, KPSS).
  - Обнаружение выбросов.
  - Визуализацию данных (графики ряда, спектров, распределение ошибок).
- Генерирует отчет в словаре `report`.

**3. Класс `TimeSeriesClass`**  
Наследуется от `TimeSeriesProcessor` и решает задачу прогнозирования:
- `get_item_series()`: Формирует временной ряд для конкретного товара
- `evaluate_models()`: Оценивает качество моделей на горизонтах 7, 30, 90 дней.
- `train_xgboost()`: Обучает XGBoost с использованием лаговых признаков.
- `remove_trend` + `restore_trend`: детрендирование ряда и восстановление, так как градиентный бустинг не умеет в экстраполяцию
- `calculate_metrics()`: Рассчитывает метрики MAE, MAPE, RMSE, SMAPE
- `full_analysis()`: Запускает полный анализ с прогнозированием для конкретного товара. Параметр `show_plots` отвечает за показ графиков анализа ряда (по умолчанию False)

**Пример работы методов**:
```python
processor = TimeSeriesProcessor()
cleaned_series = processor.preprocess(raw_series)  # Предобработка
analysis = TimeSeriesAnalysis()
report = analysis.run_analysis(cleaned_series)     # Анализ
forecaster = TimeSeriesClass(store, dates, prices)
forecaster.full_analysis("product_123")            # Прогнозирование
```

---

### Ответы на вопросы

**1. Какие методы предобработки данных вы использовали? Почему пробовали именно их?**  
Использованы:
- **Удаление начальных нулей** для исключения некорректных записей.
- **Изоляция выбросов через IsolationForest** с заменой на скользящую медиану (устойчив к аномалиям).
- **Сдвиг на 1 и обрезание отрицательных значений** для стабилизации дисперсии.  
Эти методы устраняют артефакты данных и снижают влияние шумов на модель.

---

**2. Какие модели пробовали? Почему пробовали именно их?**  
1. **ARIMA/SARIMA(прошлое задание)**  
   - **Причина выбора**: Классические модели для стационарных рядов с сезонностью.  
   - **Результаты**: Хорошая интерпретируемость, но низкая точность на рядах с нелинейными зависимостями. Требовалась ручная настройка параметров `(p, d, q)(P, D, Q, s)`.

2. **Prophet**  
   - **Причина выбора**: Автоматическое определение тренда и сезонности.  
   - **Результаты**: Эффективен на данных с явными сезонными паттернами, но плохо адаптируется к аномалиям и шумам.

3. **LSTM**  
   - **Причина выбора**: Улавливает сложные временные зависимости.  
   - **Результаты**: Требовал большого объема данных для обучения.Время обучения в 3–5 раз выше, чем у XGBoost.

4. **Transformer**  
   - **Причина выбора**: Потенциально лучшее качество на длинных последовательностях.  
   - **Результаты**: Избыточная сложность для рядов с ежедневной частотой. Неоправданные вычислительные затраты.

5. **XGBoost(с редукционным подходом) - выбран в этом задании**  
   - **Причина выбора**:  
     - Работает с нелинейными зависимостями и пропусками в данных.  
     - Автоматический учет лаговых признаков через `window_length`.  
     - Рекуррентная стратегия (`strategy="recursive"`) позволяет прогнозировать многократные горизонты.
     - Быстрое обучение и возможность интерпретации (feature importance).  
   - **Результаты**: Лучший баланс точности и скорости. Среднее улучшение RMSE на 15–20% по сравнению с классическими моделями

**Почему выбран XGBoost?**  
- **Интерпретируемость**: Возможность анализа важности лаговых признаков.  
- **Скорость**: Обучение за 5–10 сек. на CPU vs 1–2 мин. для LSTM на GPU.  
- **Устойчивость к шумам**: Деревья менее чувствительны к выбросам, чем нейросети.  
- **Гибкость**: Легко адаптируется к разным горизонтам прогнозирования (7/30/90 дней).

---

**3. Как вы проверяете качество модели? На каких данных? Какие метрики используете? Чем обусловлен выбор именно этих метрик?**  
- **Данные**: Берем тестовый набор — последние `horizon` точек ряда (7/30/90 дней).
- **Метрики**:
  - **MAE** — средняя абсолютная ошибка.
  - **MAPE** — относительная ошибка в процентах.
  - **RMSE** — чувствительность к крупным ошибкам.  
  - **SMAPE** — устраняет асимметрию: не штрафует за прогнозы ниже истинных значений сильнее, чем за завышенные + Устойчив к нулевым значениям (в отличие от MAPE, где деление на ноль невозможно).
---

**4. Какой подход из испробованных самый оптимальный с точки зрения качества прогнозирования?**  
- **XGBoost** показал лучшую сбалансированность между точностью и скоростью обучения. Результаты улучшаются за счет:
  - Автоматического учета тренда и сезонности через лаговые признаки.
  - Настройки гиперпараметров (`n_estimators=500`, `max_depth=5`).
- XGBoost обеспечивает лучшее качество при минимальных вычислительных затратах. Нейросети (LSTM, Transformer) не показали значимого улучшения, чтобы оправдать их использование.
---

**5. Какое итоговое качество модели на тестовом датасете?**  
- для каждого продукта после графика выводим сразу и метрики в отчете выше
- Например для продукта Product  STORE_1_727
  - horizon - 7:
    - 'MAE':      1.162294524056571
    - 'MAPE (%)': 41.52904646737235
    - 'RMSE':     1.6990565465771172
    - 'SMAPE':    29.541161253731858
  - horizon - 30:
    - 'MAE': 1.947886308034261
    - 'MAPE (%)': 68.76767716615917
    - 'RMSE': 2.531729205119354
    - 'SMAPE': 54.347464211743
  - horizon - 90:
    - 'MAE': 2.4220402876536054
    - 'MAPE (%)': 72.09252671610952
    - 'RMSE': 3.058478340300865
    - 'SMAPE': 61.67745000027577
